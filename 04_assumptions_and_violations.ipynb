{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 🌪️ 완벽하지 않은 현실: 가정 위반과 Welch의 해법\n",
    "\n",
    "## 📖 1947년, 새로운 영웅의 등장\n",
    "\n",
    "Student의 t-검정이 널리 사용되던 1947년, **Bernard Lewis Welch**라는 수학자가 중요한 문제를 제기했습니다:\n",
    "\n",
    "> \"두 그룹의 분산이 다르면 어떻게 해야 할까? 🤔  \n",
    "> Student's t-test는 등분산을 가정하는데...  \n",
    "> 현실에서는 이 가정이 자주 위반된다!\"\n",
    "\n",
    "이 질문이 **Welch's t-test**의 탄생으로 이어졌습니다! 🚀\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 학습 목표\n",
    "\n",
    "1. **t-검정의 3대 가정**을 이해하고 확인하는 방법 학습\n",
    "2. **등분산성 위반**의 영향과 탐지 방법\n",
    "3. **Welch's t-test**와 **Satterthwaite 근사법** 이해\n",
    "4. **가정 위반 시 대처 전략** 수립\n",
    "5. **강건성 vs 민감성** 판단 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from ipywidgets import interact, widgets, IntSlider, FloatSlider\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🌪️ 현실의 복잡함과 마주할 준비 완료!\")\n",
    "print(\"🛡️ Welch의 지혜를 배워보세요!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumptions",
   "metadata": {},
   "source": "## 📋 1. t-검정의 3대 가정\n\nStudent's t-검정이 올바르게 작동하려면 다음 3가지 가정이 충족되어야 합니다:\n\n### 🎯 **가정 1: 정규성 (Normality)**\n- **내용**: 데이터가 정규분포를 따름\n- **검정방법**: Shapiro-Wilk 검정, Q-Q plot\n- **위반시 영향**: p-값의 정확도 저하\n\n### ⚖️ **가정 2: 등분산성 (Homoscedasticity)**\n- **내용**: 두 그룹의 분산이 같음\n- **검정방법**: Levene 검정, F-검정\n- **위반시 영향**: 제1종 오류율 증가\n\n### 🔄 **가정 3: 독립성 (Independence)**\n- **내용**: 관측값들이 서로 독립\n- **검정방법**: 연구 설계로 확보\n- **위반시 영향**: 모든 통계적 추론 무효\n\n### 💡 **현실에서는...**\n- **정규성**: 표본크기가 클수록 덜 중요 (중심극한정리)\n- **등분산성**: 가장 자주 위반되는 가정\n- **독립성**: 가장 중요하지만 통계적 검정 불가\n\n---\n\n## 🎭 통계적 오류의 두 가지 유형\n\n### 📊 **가설검정의 4가지 결과**\n\n|  | 실제 H₀ 참 | 실제 H₀ 거짓 |\n|---|------------|--------------|\n| **H₀ 기각** | 🚨 제1종 오류 (α) | ✅ 올바른 기각 (검정력) |\n| **H₀ 채택** | ✅ 올바른 채택 | 😔 제2종 오류 (β) |\n\n### 🚨 **제1종 오류 (Type I Error)**\n- **정의**: 실제로는 차이가 없는데 차이가 있다고 결론\n- **확률**: α (유의수준, 보통 0.05)\n- **비유**: \"무죄인 사람을 유죄로 판결\"\n- **예시**: \n  - 효과 없는 약을 효과 있다고 판단\n  - 정상 제품을 불량이라고 판정\n  - 차이 없는 두 그룹을 다르다고 결론\n\n### 😔 **제2종 오류 (Type II Error)**\n- **정의**: 실제로는 차이가 있는데 차이가 없다고 결론\n- **확률**: β\n- **비유**: \"유죄인 사람을 무죄로 판결\"\n- **예시**:\n  - 효과 있는 약을 효과 없다고 판단\n  - 불량 제품을 정상이라고 판정\n  - 다른 두 그룹을 같다고 결론\n\n### ⚡ **검정력 (Statistical Power)**\n- **정의**: 실제로 차이가 있을 때 이를 올바르게 탐지할 확률\n- **공식**: Power = 1 - β\n- **목표**: 보통 0.8 이상\n\n### 💡 **왜 제1종 오류가 중요한가?**\n\n#### 등분산성 위반 시:\n- Student's t-test의 제1종 오류율이 명목수준(α=0.05)을 초과\n- 예: 실제 5%여야 할 오류율이 10%로 증가\n- **결과**: 없는 차이를 있다고 잘못 판단할 위험 증가\n\n#### Welch's t-test의 장점:\n- 등분산 가정 없이도 제1종 오류율을 α 수준으로 유지\n- 더 보수적이고 안전한 검정\n\n### 📈 **실제 예시: 제1종 오류의 위험**\n\n```python\n# 귀무가설이 참일 때 (실제로 차이 없음)\n# α = 0.05로 설정했지만...\n\n# 등분산 가정 만족 시:\n# → 100번 중 5번 정도 잘못된 기각 (정상)\n\n# 등분산 가정 위반 시:\n# → 100번 중 10번 이상 잘못된 기각! (문제!)\n# → 거짓 양성 결과 2배 증가\n```\n\n### 🎯 **오류 최소화 전략**\n\n1. **제1종 오류 통제**: \n   - 유의수준 α 설정 (보통 0.05)\n   - 적절한 검정 방법 선택 (Welch's t-test)\n\n2. **제2종 오류 감소**:\n   - 표본크기 증가\n   - 측정 정밀도 향상\n   - 효과크기가 클 것으로 예상되는 연구 설계\n\n3. **균형 찾기**:\n   - α를 너무 낮추면 → β 증가 (검정력 감소)\n   - α를 너무 높이면 → 거짓 양성 증가\n   - 일반적으로 α=0.05, Power=0.8 목표"
  },
  {
   "cell_type": "markdown",
   "id": "l9eta1sks8k",
   "source": "## 🔍 등분산성 검정 방법들\n\n### 📊 **등분산성(Homogeneity of Variance)이란?**\n\n두 그룹의 모집단 분산이 같다는 가정: σ₁² = σ₂²\n\n### 🧪 **주요 검정 방법**\n\n#### 1. **Levene 검정** (가장 권장)\n```python\nfrom scipy import stats\nstat, p_value = stats.levene(group1, group2)\n\n# 해석\nif p_value > 0.05:\n    print(\"등분산 가정 만족\")\nelse:\n    print(\"등분산 가정 위반 → Welch's t-test 사용\")\n```\n\n**특징**:\n- 정규성 가정에 강건함\n- 평균 또는 중앙값 기준 선택 가능\n- 실무에서 가장 많이 사용\n\n#### 2. **Bartlett 검정**\n```python\nstat, p_value = stats.bartlett(group1, group2)\n```\n\n**특징**:\n- 정규성 가정에 민감함\n- 데이터가 정규분포일 때만 사용\n- Levene보다 검정력 높음 (정규분포 시)\n\n#### 3. **F-검정**\n```python\nvar_ratio = np.var(group1, ddof=1) / np.var(group2, ddof=1)\ndf1, df2 = len(group1) - 1, len(group2) - 1\np_value = 2 * min(stats.f.cdf(var_ratio, df1, df2),\n                  1 - stats.f.cdf(var_ratio, df1, df2))\n```\n\n**특징**:\n- 두 분산의 비율 직접 검정\n- 정규성 가정 필요\n- 가장 단순한 방법\n\n### 📈 **분산비 경험 규칙**\n\n```python\n# 실용적 판단 기준\nvariance_ratio = max(var1, var2) / min(var1, var2)\n\nif variance_ratio < 2:\n    print(\"등분산으로 간주 가능\")\nelif variance_ratio < 4:\n    print(\"경계선 - Welch's 권장\")\nelse:\n    print(\"명확한 이분산 - Welch's 필수!\")\n```\n\n### 💡 **중요 참고사항**\n\n1. **검정의 한계**: \n   - 작은 표본: 검정력 부족 (이분산을 놓칠 수 있음)\n   - 큰 표본: 사소한 차이도 유의하게 나옴\n\n2. **실무 권장**:\n   - 의심스러우면 Welch's 사용\n   - 등분산 검정 결과와 무관하게 Welch's는 안전",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zmh3zr5u9mc",
   "source": "# 🔬 등분산일 때 Student's vs Welch's 비교 실험\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ndef compare_student_vs_welch():\n    \"\"\"등분산일 때 Student's와 Welch's t-test 결과 비교\"\"\"\n    \n    print(\"=\" * 70)\n    print(\"🔬 등분산일 때 Student's vs Welch's t-test 비교\")\n    print(\"=\" * 70)\n    \n    # 시나리오 설정\n    scenarios = [\n        # (n1, n2, mean1, mean2, std, 설명)\n        (30, 30, 100, 100, 10, \"동일 조건 (H₀ 참)\"),\n        (30, 30, 100, 103, 10, \"작은 차이\"),\n        (30, 30, 100, 105, 10, \"중간 차이\"),\n        (50, 50, 100, 100, 10, \"큰 표본 (H₀ 참)\"),\n        (20, 40, 100, 100, 10, \"불균등 표본 (H₀ 참)\"),\n        (20, 40, 100, 105, 10, \"불균등 표본 + 차이\")\n    ]\n    \n    results = []\n    \n    for n1, n2, mean1, mean2, std, description in scenarios:\n        # 등분산 데이터 생성 (같은 표준편차)\n        np.random.seed(42)\n        group1 = np.random.normal(mean1, std, n1)\n        group2 = np.random.normal(mean2, std, n2)\n        \n        # 분산 확인\n        var1 = np.var(group1, ddof=1)\n        var2 = np.var(group2, ddof=1)\n        var_ratio = max(var1, var2) / min(var1, var2)\n        \n        # Levene 검정\n        levene_stat, levene_p = stats.levene(group1, group2)\n        \n        # Student's t-test\n        t_student, p_student = stats.ttest_ind(group1, group2, equal_var=True)\n        df_student = n1 + n2 - 2\n        \n        # Welch's t-test\n        t_welch, p_welch = stats.ttest_ind(group1, group2, equal_var=False)\n        \n        # Welch's 자유도 계산\n        s1, s2 = np.std(group1, ddof=1), np.std(group2, ddof=1)\n        numerator = (s1**2/n1 + s2**2/n2)**2\n        denominator = (s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1)\n        df_welch = numerator / denominator\n        \n        results.append({\n            '시나리오': description,\n            'n1, n2': f\"({n1}, {n2})\",\n            '분산비': f\"{var_ratio:.2f}\",\n            'Levene p': f\"{levene_p:.3f}\",\n            'Student t': f\"{t_student:.3f}\",\n            'Student p': f\"{p_student:.4f}\",\n            'Student df': f\"{df_student:.0f}\",\n            'Welch t': f\"{t_welch:.3f}\",\n            'Welch p': f\"{p_welch:.4f}\",\n            'Welch df': f\"{df_welch:.1f}\",\n            't 차이': f\"{abs(t_student - t_welch):.4f}\",\n            'p 차이': f\"{abs(p_student - p_welch):.4f}\"\n        })\n    \n    # DataFrame 생성\n    df_results = pd.DataFrame(results)\n    \n    print(\"\\n📊 결과 테이블:\")\n    print(df_results.to_string(index=False))\n    \n    # 시각화: 1000회 시뮬레이션\n    print(\"\\n\" + \"=\" * 70)\n    print(\"📈 1000회 시뮬레이션: 등분산일 때 두 검정의 일치도\")\n    print(\"=\" * 70)\n    \n    np.random.seed(42)\n    n_simulations = 1000\n    t_differences = []\n    p_differences = []\n    \n    for _ in range(n_simulations):\n        # 등분산 데이터 생성\n        g1 = np.random.normal(100, 10, 30)\n        g2 = np.random.normal(102, 10, 30)  # 같은 분산!\n        \n        # 두 검정 수행\n        t_s, p_s = stats.ttest_ind(g1, g2, equal_var=True)\n        t_w, p_w = stats.ttest_ind(g1, g2, equal_var=False)\n        \n        t_differences.append(abs(t_s - t_w))\n        p_differences.append(abs(p_s - p_w))\n    \n    # 히스토그램 생성\n    fig = make_subplots(\n        rows=1, cols=2,\n        subplot_titles=[\n            't-통계량 차이 분포',\n            'p-값 차이 분포'\n        ]\n    )\n    \n    fig.add_trace(\n        go.Histogram(x=t_differences, nbinsx=50, \n                     marker_color='blue', opacity=0.7,\n                     name='|t_student - t_welch|'),\n        row=1, col=1\n    )\n    \n    fig.add_trace(\n        go.Histogram(x=p_differences, nbinsx=50,\n                     marker_color='green', opacity=0.7,\n                     name='|p_student - p_welch|'),\n        row=1, col=2\n    )\n    \n    fig.update_layout(\n        title='🔬 등분산일 때 Student vs Welch 차이 (1000회 시뮬레이션)',\n        height=400\n    )\n    \n    fig.update_xaxes(title_text='t-통계량 절대 차이', row=1, col=1)\n    fig.update_xaxes(title_text='p-값 절대 차이', row=1, col=2)\n    fig.update_yaxes(title_text='빈도', row=1, col=1)\n    \n    print(f\"\\n📊 시뮬레이션 결과:\")\n    print(f\"  • t-통계량 평균 차이: {np.mean(t_differences):.6f}\")\n    print(f\"  • t-통계량 최대 차이: {np.max(t_differences):.6f}\")\n    print(f\"  • p-값 평균 차이: {np.mean(p_differences):.6f}\")\n    print(f\"  • p-값 최대 차이: {np.max(p_differences):.6f}\")\n    \n    print(\"\\n💡 핵심 발견:\")\n    print(\"  1. 등분산일 때 두 검정의 t-통계량은 동일!\")\n    print(\"  2. p-값도 거의 동일 (미세한 차이는 자유도 차이 때문)\")\n    print(\"  3. 균등 표본일 때 자유도도 거의 같음\")\n    print(\"  4. 결론: 등분산이면 Welch's ≈ Student's\")\n    print(\"\\n🎯 하지만 Welch's는 이분산일 때도 안전하므로\")\n    print(\"   → 항상 Welch's 사용이 권장됨!\")\n    \n    return fig\n\n# 실험 실행\nfig = compare_student_vs_welch()\nfig.show()\n\n# ====================================================\n# 수학적 증명: 등분산일 때 왜 같은가?\n# ====================================================\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"📐 수학적 설명: 등분산일 때 왜 결과가 같은가?\")\nprint(\"=\" * 70)\n\nprint(\"\"\"\nStudent's t-test:\n  t = (X̄₁ - X̄₂) / (sp × √(1/n₁ + 1/n₂))\n  여기서 sp² = ((n₁-1)s₁² + (n₂-1)s₂²) / (n₁+n₂-2)\n\nWelch's t-test:\n  t = (X̄₁ - X̄₂) / √(s₁²/n₁ + s₂²/n₂)\n\n등분산일 때 (s₁² ≈ s₂² = s²):\n  \n  Student's 분모:\n    sp × √(1/n₁ + 1/n₂) ≈ s × √(1/n₁ + 1/n₂)\n  \n  Welch's 분모:\n    √(s²/n₁ + s²/n₂) = s × √(1/n₁ + 1/n₂)\n  \n  → 두 분모가 같아짐!\n  → t-통계량이 (거의) 동일!\n\n특히 n₁ = n₂일 때:\n  자유도도 거의 같아짐 (Student: n₁+n₂-2, Welch: ≈ n₁+n₂-2)\n  \n결론: 등분산 + 균등표본 → 두 검정 완전 일치!\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "welch-theory",
   "metadata": {},
   "source": "## 🛡️ 2. Welch's t-test: 현실적 해법\n\n### 🤔 **등분산성 위반의 문제점**\n\nStudent's t-검정은 두 그룹의 분산이 같다고 가정합니다:\n$$t = \\frac{\\bar{X_1} - \\bar{X_2}}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\n\n여기서 **pooled standard deviation**:\n$$s_p = \\sqrt{\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}$$\n\n### ⚠️ **문제점**:\n- 두 그룹의 분산이 실제로 다르면 $s_p$가 부적절\n- 제1종 오류율이 명목수준 0.05를 초과\n- 특히 표본크기가 다를 때 심각\n\n### 🚀 **Welch의 해법**:\n\n$$t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$$\n\n**핵심 아이디어**: 각 그룹의 분산을 따로 계산!\n\n### 📊 **Satterthwaite 근사법**:\n\n자유도를 다음과 같이 근사:\n$$\\nu = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{s_1^4}{n_1^2(n_1-1)} + \\frac{s_2^4}{n_2^2(n_2-1)}}$$\n\n**결과**: 정수가 아닌 자유도가 나올 수 있음!\n\n---\n\n## 🏥 등분산이 아닌 실제 상황들\n\n### 📚 **언제 등분산이 깨지나요?**\n\n등분산(equal variance) 가정은 현실에서 자주 위반됩니다. 다음과 같은 상황들이 대표적입니다:\n\n#### 1. **🏢 대기업 vs 스타트업 연봉 비교**\n- **대기업**: 체계적인 연봉 테이블 → 작은 분산\n- **스타트업**: 스톡옵션, 성과급 변동 → 큰 분산\n- 평균은 비슷해도 분산이 크게 다름!\n\n#### 2. **👶 신생아 vs 청소년 키 분포**\n- **신생아**: 키 차이가 작음 (45-55cm) → 작은 분산\n- **청소년**: 성장 속도 차이로 키 차이가 큼 (140-190cm) → 큰 분산\n- 나이가 들수록 개인차가 커짐\n\n#### 3. **🎓 초급반 vs 고급반 시험 점수**\n- **초급반**: 대부분 비슷한 수준 → 작은 분산\n- **고급반**: 실력 차이가 벌어짐 → 큰 분산\n- 학습이 진행될수록 격차 증가\n\n#### 4. **💊 신약 vs 위약 치료 효과**\n- **위약군**: 거의 변화 없음 → 작은 분산\n- **신약군**: 개인별 반응 차이 → 큰 분산\n- 약물 반응의 개인차가 크게 나타남\n\n#### 5. **🏠 도심 vs 교외 주택 가격**\n- **교외**: 비슷한 주택들 → 작은 분산\n- **도심**: 원룸부터 펜트하우스까지 → 큰 분산\n- 지역에 따라 다양성이 다름"
  },
  {
   "cell_type": "code",
   "id": "wov5hf6lsw",
   "source": "# 🔬 등분산 vs 이분산 실제 예제 코드\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# 한글 폰트 설정\nplt.rcParams['font.family'] = 'DejaVu Sans'\nplt.rcParams['axes.unicode_minus'] = False\n\n# 시드 설정\nnp.random.seed(42)\n\n# ====================================================\n# 예제 1: 대기업 vs 스타트업 연봉 비교\n# ====================================================\n\ndef salary_comparison_example():\n    \"\"\"대기업과 스타트업의 연봉 분포 비교 - 이분산의 전형적 예제\"\"\"\n    \n    # 데이터 생성\n    # 대기업: 평균 6000만원, 표준편차 500만원 (체계적 연봉 테이블)\n    corporate_salaries = np.random.normal(6000, 500, 100)\n    \n    # 스타트업: 평균 6200만원, 표준편차 1500만원 (큰 변동성)\n    startup_salaries = np.random.normal(6200, 1500, 80)\n    \n    # 음수 제거\n    corporate_salaries = np.abs(corporate_salaries)\n    startup_salaries = np.abs(startup_salaries)\n    \n    # 등분산성 검정\n    levene_stat, levene_p = stats.levene(corporate_salaries, startup_salaries)\n    \n    # Student's t-test (등분산 가정)\n    t_stat_student, p_val_student = stats.ttest_ind(corporate_salaries, startup_salaries)\n    \n    # Welch's t-test (등분산 가정 안함)\n    t_stat_welch, p_val_welch = stats.ttest_ind(corporate_salaries, startup_salaries, equal_var=False)\n    \n    # 시각화\n    fig = make_subplots(\n        rows=2, cols=2,\n        subplot_titles=[\n            '1. 연봉 분포 비교',\n            '2. 분산 차이 시각화',\n            '3. 박스플롯 비교',\n            '4. 검정 결과 비교'\n        ],\n        specs=[\n            [{'type': 'histogram'}, {'type': 'scatter'}],\n            [{'type': 'box'}, {'type': 'bar'}]\n        ]\n    )\n    \n    # 1. 히스토그램\n    fig.add_trace(\n        go.Histogram(x=corporate_salaries, name='대기업', opacity=0.6, \n                     nbinsx=20, marker_color='blue'),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Histogram(x=startup_salaries, name='스타트업', opacity=0.6,\n                     nbinsx=20, marker_color='red'),\n        row=1, col=1\n    )\n    \n    # 2. 분산 비교 (산점도)\n    fig.add_trace(\n        go.Scatter(x=np.random.uniform(0.8, 1.2, len(corporate_salaries)),\n                   y=corporate_salaries, mode='markers', name='대기업',\n                   marker=dict(color='blue', size=3, opacity=0.5)),\n        row=1, col=2\n    )\n    fig.add_trace(\n        go.Scatter(x=np.random.uniform(1.8, 2.2, len(startup_salaries)),\n                   y=startup_salaries, mode='markers', name='스타트업',\n                   marker=dict(color='red', size=3, opacity=0.5)),\n        row=1, col=2\n    )\n    \n    # 평균선 추가\n    fig.add_hline(y=np.mean(corporate_salaries), line_dash=\"solid\", \n                  line_color=\"blue\", row=1, col=2)\n    fig.add_hline(y=np.mean(startup_salaries), line_dash=\"solid\",\n                  line_color=\"red\", row=1, col=2)\n    \n    # 3. 박스플롯\n    fig.add_trace(\n        go.Box(y=corporate_salaries, name='대기업', marker_color='blue'),\n        row=2, col=1\n    )\n    fig.add_trace(\n        go.Box(y=startup_salaries, name='스타트업', marker_color='red'),\n        row=2, col=1\n    )\n    \n    # 4. 검정 결과 비교\n    test_names = ['Student\\'s t-test', 'Welch\\'s t-test']\n    p_values = [p_val_student, p_val_welch]\n    colors = ['orange' if p > 0.05 else 'green' for p in p_values]\n    \n    fig.add_trace(\n        go.Bar(x=test_names, y=p_values, marker_color=colors,\n               text=[f'p={p:.4f}' for p in p_values], textposition='auto'),\n        row=2, col=2\n    )\n    \n    # 유의수준 선\n    fig.add_hline(y=0.05, line_dash=\"dash\", line_color=\"red\",\n                  annotation_text=\"α=0.05\", row=2, col=2)\n    \n    # 레이아웃 설정\n    fig.update_layout(\n        title='🏢 대기업 vs 스타트업 연봉 비교 (이분산 예제)',\n        height=800,\n        showlegend=True\n    )\n    \n    fig.update_xaxes(title_text='연봉 (만원)', row=1, col=1)\n    fig.update_xaxes(title_text='그룹', row=1, col=2)\n    fig.update_yaxes(title_text='연봉 (만원)', row=1, col=2)\n    fig.update_yaxes(title_text='연봉 (만원)', row=2, col=1)\n    fig.update_yaxes(title_text='p-value', row=2, col=2)\n    \n    # 결과 출력\n    print(\"=\" * 70)\n    print(\"🏢 대기업 vs 스타트업 연봉 비교 분석\")\n    print(\"=\" * 70)\n    print(f\"\\n📊 기초 통계량:\")\n    print(f\"  대기업: 평균 = {np.mean(corporate_salaries):.0f}만원, 표준편차 = {np.std(corporate_salaries, ddof=1):.0f}만원\")\n    print(f\"  스타트업: 평균 = {np.mean(startup_salaries):.0f}만원, 표준편차 = {np.std(startup_salaries, ddof=1):.0f}만원\")\n    print(f\"\\n🔍 분산비 = {np.var(startup_salaries, ddof=1) / np.var(corporate_salaries, ddof=1):.2f} (스타트업/대기업)\")\n    print(f\"\\n📈 Levene 검정 (등분산성):\")\n    print(f\"  통계량 = {levene_stat:.3f}, p-value = {levene_p:.4f}\")\n    print(f\"  결론: {'등분산 가정 위반 ❌' if levene_p < 0.05 else '등분산 가정 만족 ✅'}\")\n    print(f\"\\n🎯 t-검정 결과 비교:\")\n    print(f\"  Student's t-test: t = {t_stat_student:.3f}, p = {p_val_student:.4f}\")\n    print(f\"  Welch's t-test:   t = {t_stat_welch:.3f}, p = {p_val_welch:.4f}\")\n    print(f\"\\n💡 해석:\")\n    print(f\"  - 분산이 {np.var(startup_salaries, ddof=1) / np.var(corporate_salaries, ddof=1):.1f}배 차이남\")\n    print(f\"  - 이런 경우 Welch's t-test가 더 적절\")\n    print(f\"  - {'두 검정 모두 유의한 차이 없음' if p_val_welch > 0.05 else '유의한 차이 있음'}\")\n    \n    return fig\n\n# 예제 1 실행\nfig1 = salary_comparison_example()\nfig1.show()\n\n# ====================================================\n# 예제 2: 신약 vs 위약 치료 효과 (극단적 이분산)\n# ====================================================\n\ndef drug_effect_example():\n    \"\"\"신약과 위약의 치료 효과 비교 - 극단적 이분산 예제\"\"\"\n    \n    # 데이터 생성\n    # 위약군: 거의 변화 없음 (평균 0, 표준편차 2)\n    placebo_effect = np.random.normal(0, 2, 50)\n    \n    # 신약군: 개인차 큼 (평균 5, 표준편차 10)\n    drug_effect = np.random.normal(5, 10, 50)\n    \n    # 통계 분석\n    levene_stat, levene_p = stats.levene(placebo_effect, drug_effect)\n    \n    # 두 가지 t-test\n    t_student, p_student = stats.ttest_ind(placebo_effect, drug_effect)\n    t_welch, p_welch = stats.ttest_ind(placebo_effect, drug_effect, equal_var=False)\n    \n    # 자유도 계산\n    n1, n2 = len(placebo_effect), len(drug_effect)\n    s1, s2 = np.std(placebo_effect, ddof=1), np.std(drug_effect, ddof=1)\n    \n    # Student's t-test 자유도\n    df_student = n1 + n2 - 2\n    \n    # Welch's t-test 자유도 (Satterthwaite 근사)\n    numerator = (s1**2/n1 + s2**2/n2)**2\n    denominator = (s1**2/n1)**2/(n1-1) + (s2**2/n2)**2/(n2-1)\n    df_welch = numerator / denominator\n    \n    # 시각화\n    fig = make_subplots(\n        rows=1, cols=3,\n        subplot_titles=[\n            '치료 효과 분포',\n            '분산 차이 (Violin plot)',\n            '자유도 비교'\n        ]\n    )\n    \n    # 1. 히스토그램\n    fig.add_trace(\n        go.Histogram(x=placebo_effect, name='위약', opacity=0.7,\n                     nbinsx=20, marker_color='gray'),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Histogram(x=drug_effect, name='신약', opacity=0.7,\n                     nbinsx=20, marker_color='green'),\n        row=1, col=1\n    )\n    \n    # 2. Violin plot\n    fig.add_trace(\n        go.Violin(y=placebo_effect, name='위약', box_visible=True,\n                  marker_color='gray'),\n        row=1, col=2\n    )\n    fig.add_trace(\n        go.Violin(y=drug_effect, name='신약', box_visible=True,\n                  marker_color='green'),\n        row=1, col=2\n    )\n    \n    # 3. 자유도 비교\n    fig.add_trace(\n        go.Bar(x=['Student\\'s', 'Welch\\'s'], \n               y=[df_student, df_welch],\n               text=[f'df={df_student:.0f}', f'df={df_welch:.1f}'],\n               textposition='auto',\n               marker_color=['blue', 'orange']),\n        row=1, col=3\n    )\n    \n    fig.update_layout(\n        title='💊 신약 vs 위약 치료 효과 (극단적 이분산)',\n        height=400,\n        showlegend=True\n    )\n    \n    # 결과 출력\n    print(\"\\n\" + \"=\" * 70)\n    print(\"💊 신약 vs 위약 치료 효과 분석\")\n    print(\"=\" * 70)\n    print(f\"\\n📊 기초 통계량:\")\n    print(f\"  위약: 평균 = {np.mean(placebo_effect):.2f}, 표준편차 = {s1:.2f}\")\n    print(f\"  신약: 평균 = {np.mean(drug_effect):.2f}, 표준편차 = {s2:.2f}\")\n    print(f\"\\n🔍 분산비 = {s2**2 / s1**2:.2f} (신약/위약)\")\n    print(f\"\\n📈 등분산성 검정:\")\n    print(f\"  Levene: F = {levene_stat:.3f}, p = {levene_p:.6f}\")\n    print(f\"  결론: 극단적인 이분산! ❌❌❌\")\n    print(f\"\\n🎯 자유도 차이:\")\n    print(f\"  Student's t-test: df = {df_student:.0f} (정수)\")\n    print(f\"  Welch's t-test:   df = {df_welch:.1f} (소수)\")\n    print(f\"  차이: {df_student - df_welch:.1f} 감소\")\n    print(f\"\\n📊 검정 결과:\")\n    print(f\"  Student's: t = {t_student:.3f}, p = {p_student:.4f}\")\n    print(f\"  Welch's:   t = {t_welch:.3f}, p = {p_welch:.4f}\")\n    print(f\"\\n⚠️ 경고: 분산비가 {s2**2 / s1**2:.0f}배! Welch's t-test 필수!\")\n    \n    return fig\n\n# 예제 2 실행\nfig2 = drug_effect_example()\nfig2.show()\n\n# ====================================================\n# 예제 3: 등분산 vs 이분산 시뮬레이션 비교\n# ====================================================\n\ndef variance_simulation():\n    \"\"\"등분산과 이분산 상황에서의 Type I 오류율 비교\"\"\"\n    \n    n_simulations = 1000\n    alpha = 0.05\n    sample_sizes = [(20, 20), (20, 40), (20, 60)]  # 균등/불균등 표본\n    variance_ratios = [1, 2, 4, 8]  # 분산비\n    \n    results = []\n    \n    for n1, n2 in sample_sizes:\n        for var_ratio in variance_ratios:\n            student_errors = 0\n            welch_errors = 0\n            \n            for _ in range(n_simulations):\n                # H0가 참인 상황 (평균은 같음)\n                group1 = np.random.normal(0, 1, n1)\n                group2 = np.random.normal(0, np.sqrt(var_ratio), n2)\n                \n                # Student's t-test\n                _, p_student = stats.ttest_ind(group1, group2)\n                if p_student < alpha:\n                    student_errors += 1\n                \n                # Welch's t-test\n                _, p_welch = stats.ttest_ind(group1, group2, equal_var=False)\n                if p_welch < alpha:\n                    welch_errors += 1\n            \n            results.append({\n                'Sample Size': f'({n1},{n2})',\n                'Variance Ratio': var_ratio,\n                'Student Error Rate': student_errors / n_simulations,\n                'Welch Error Rate': welch_errors / n_simulations\n            })\n    \n    # 결과를 DataFrame으로 변환\n    df_results = pd.DataFrame(results)\n    \n    # 시각화\n    fig = make_subplots(\n        rows=1, cols=3,\n        subplot_titles=[\n            '균등 표본 (20,20)',\n            '중간 불균등 (20,40)', \n            '극단 불균등 (20,60)'\n        ]\n    )\n    \n    for i, (n1, n2) in enumerate(sample_sizes):\n        sample_data = df_results[df_results['Sample Size'] == f'({n1},{n2})']\n        \n        fig.add_trace(\n            go.Scatter(x=sample_data['Variance Ratio'], \n                      y=sample_data['Student Error Rate'],\n                      mode='lines+markers', name=f'Student ({n1},{n2})',\n                      line=dict(color='red', dash='solid' if i==0 else 'dash')),\n            row=1, col=i+1\n        )\n        \n        fig.add_trace(\n            go.Scatter(x=sample_data['Variance Ratio'],\n                      y=sample_data['Welch Error Rate'],\n                      mode='lines+markers', name=f'Welch ({n1},{n2})',\n                      line=dict(color='blue', dash='solid' if i==0 else 'dash')),\n            row=1, col=i+1\n        )\n        \n        # 명목 오류율 선\n        fig.add_hline(y=alpha, line_dash=\"dash\", line_color=\"gray\",\n                     annotation_text=\"α=0.05\", row=1, col=i+1)\n    \n    fig.update_layout(\n        title='🔬 Type I 오류율: Student vs Welch (1000회 시뮬레이션)',\n        height=400\n    )\n    \n    fig.update_xaxes(title_text='분산비', row=1, col=2)\n    fig.update_yaxes(title_text='Type I 오류율', row=1, col=1)\n    \n    # 결과 테이블 출력\n    print(\"\\n\" + \"=\" * 70)\n    print(\"🔬 Type I 오류율 시뮬레이션 결과\")\n    print(\"=\" * 70)\n    print(\"\\n📊 결과 테이블:\")\n    print(df_results.to_string(index=False))\n    print(\"\\n💡 핵심 발견:\")\n    print(\"  1. 등분산(ratio=1)일 때: 두 방법 모두 α=0.05 유지\")\n    print(\"  2. 이분산 + 균등표본: Student's는 약간 상승, Welch는 안정\")\n    print(\"  3. 이분산 + 불균등표본: Student's는 크게 상승, Welch는 여전히 안정\")\n    print(\"  4. 결론: Welch's t-test가 더 강건함!\")\n    \n    return fig\n\n# 예제 3 실행\nfig3 = variance_simulation()\nfig3.show()\n\nprint(\"\\n\" + \"🎯\" * 35)\nprint(\"\\n📌 최종 요약:\")\nprint(\"  • 등분산 가정이 위반되면 Student's t-test는 부정확\")\nprint(\"  • 특히 표본크기까지 다르면 오류율 급증\")\nprint(\"  • Welch's t-test는 모든 상황에서 안정적\")\nprint(\"  • 실무 권장: 의심스러우면 Welch's 사용!\")\nprint(\"\\n\" + \"🎯\" * 35)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "o7s0uc9tl4",
   "source": "# ====================================================\n# 예제 4: 부채널 분석과 TVLA (Test Vector Leakage Assessment)\n# ====================================================\n\ndef side_channel_analysis_example():\n    \"\"\"부채널 분석에서 Welch's t-test의 중요성과 TVLA 예제\"\"\"\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"🔐 부채널 분석과 TVLA (Test Vector Leakage Assessment)\")\n    print(\"=\" * 70)\n    \n    # 암호화 장치의 전력 소비 시뮬레이션\n    np.random.seed(42)\n    \n    # 시나리오: 비밀키의 특정 비트가 0일 때와 1일 때의 전력 소비\n    # 실제 부채널 공격에서는 수천~수만 개의 측정값을 사용\n    \n    # 키 비트 = 0일 때의 전력 소비 (기본 소비 + 작은 노이즈)\n    n_traces_0 = 1000\n    power_key0 = np.random.normal(100, 5, n_traces_0)  # 평균 100mW, 표준편차 5mW\n    \n    # 키 비트 = 1일 때의 전력 소비 (추가 연산으로 약간 높음 + 큰 노이즈)\n    n_traces_1 = 800\n    # 중요: 실제로 분산이 다름! (추가 연산시 변동성 증가)\n    power_key1 = np.random.normal(102, 15, n_traces_1)  # 평균 102mW, 표준편차 15mW\n    \n    # 등분산성 검정\n    levene_stat, levene_p = stats.levene(power_key0, power_key1)\n    \n    # Student's t-test vs Welch's t-test\n    t_student, p_student = stats.ttest_ind(power_key0, power_key1)\n    t_welch, p_welch = stats.ttest_ind(power_key0, power_key1, equal_var=False)\n    \n    # TVLA 기준: |t| > 4.5 이면 누설 탐지\n    tvla_threshold = 4.5\n    \n    print(f\"\\n📊 전력 소비 분석:\")\n    print(f\"  키=0: 평균 = {np.mean(power_key0):.2f}mW, 표준편차 = {np.std(power_key0, ddof=1):.2f}mW\")\n    print(f\"  키=1: 평균 = {np.mean(power_key1):.2f}mW, 표준편차 = {np.std(power_key1, ddof=1):.2f}mW\")\n    print(f\"\\n🔍 분산비 = {np.var(power_key1, ddof=1) / np.var(power_key0, ddof=1):.2f}\")\n    print(f\"  → 키=1일 때 분산이 {np.var(power_key1, ddof=1) / np.var(power_key0, ddof=1):.1f}배 큼!\")\n    \n    print(f\"\\n📈 등분산성 검정:\")\n    print(f\"  Levene: p = {levene_p:.6f}\")\n    print(f\"  결론: {'등분산 가정 위반! ❌' if levene_p < 0.05 else '등분산 가정 만족'}\")\n    \n    print(f\"\\n🎯 TVLA 검정 결과:\")\n    print(f\"  Student's t-test: |t| = {abs(t_student):.3f}\")\n    print(f\"  Welch's t-test:   |t| = {abs(t_welch):.3f}\")\n    print(f\"  TVLA 임계값: {tvla_threshold}\")\n    print(f\"\\n  Student's 결론: {'누설 탐지! 🚨' if abs(t_student) > tvla_threshold else '안전'}\")\n    print(f\"  Welch's 결론:   {'누설 탐지! 🚨' if abs(t_welch) > tvla_threshold else '안전'}\")\n    \n    # 시각화\n    fig = make_subplots(\n        rows=2, cols=2,\n        subplot_titles=[\n            '전력 소비 분포',\n            'TVLA 검정 결과',\n            '시간에 따른 전력 파형',\n            '누설 탐지 임계값'\n        ]\n    )\n    \n    # 1. 전력 소비 분포\n    fig.add_trace(\n        go.Histogram(x=power_key0, name='Key=0', opacity=0.7,\n                     nbinsx=30, marker_color='blue'),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Histogram(x=power_key1, name='Key=1', opacity=0.7,\n                     nbinsx=30, marker_color='red'),\n        row=1, col=1\n    )\n    \n    # 2. TVLA 검정 결과 비교\n    test_names = ['Student\\'s', 'Welch\\'s']\n    t_values = [abs(t_student), abs(t_welch)]\n    colors = ['red' if t > tvla_threshold else 'green' for t in t_values]\n    \n    fig.add_trace(\n        go.Bar(x=test_names, y=t_values, marker_color=colors,\n               text=[f'|t|={t:.2f}' for t in t_values], textposition='auto'),\n        row=1, col=2\n    )\n    fig.add_hline(y=tvla_threshold, line_dash=\"dash\", line_color=\"red\",\n                  annotation_text=\"TVLA 임계값 (4.5)\", row=1, col=2)\n    \n    # 3. 시간에 따른 전력 파형 (실제 측정 시뮬레이션)\n    time_points = 100\n    time = np.arange(time_points)\n    \n    # 키=0일 때 평균 파형\n    waveform_key0 = 100 + 2 * np.sin(time * 0.1) + np.random.normal(0, 0.5, time_points)\n    # 키=1일 때 평균 파형 (특정 시점에 스파이크)\n    waveform_key1 = 100 + 2 * np.sin(time * 0.1) + np.random.normal(0, 0.5, time_points)\n    waveform_key1[40:45] += 5  # 암호 연산 시점\n    \n    fig.add_trace(\n        go.Scatter(x=time, y=waveform_key0, mode='lines', name='Key=0',\n                   line=dict(color='blue', width=2)),\n        row=2, col=1\n    )\n    fig.add_trace(\n        go.Scatter(x=time, y=waveform_key1, mode='lines', name='Key=1',\n                   line=dict(color='red', width=2)),\n        row=2, col=1\n    )\n    \n    # 4. 다양한 노이즈 레벨에서의 탐지 성능\n    noise_levels = np.arange(1, 20, 2)\n    detection_student = []\n    detection_welch = []\n    \n    for noise in noise_levels:\n        # 100회 반복하여 평균 탐지율 계산\n        student_detect = 0\n        welch_detect = 0\n        \n        for _ in range(100):\n            sample0 = np.random.normal(100, 5, 100)\n            sample1 = np.random.normal(102, noise, 100)\n            \n            t_s, _ = stats.ttest_ind(sample0, sample1)\n            t_w, _ = stats.ttest_ind(sample0, sample1, equal_var=False)\n            \n            if abs(t_s) > tvla_threshold:\n                student_detect += 1\n            if abs(t_w) > tvla_threshold:\n                welch_detect += 1\n        \n        detection_student.append(student_detect)\n        detection_welch.append(welch_detect)\n    \n    fig.add_trace(\n        go.Scatter(x=noise_levels, y=detection_student, mode='lines+markers',\n                   name='Student\\'s', line=dict(color='orange', width=2)),\n        row=2, col=2\n    )\n    fig.add_trace(\n        go.Scatter(x=noise_levels, y=detection_welch, mode='lines+markers',\n                   name='Welch\\'s', line=dict(color='green', width=2)),\n        row=2, col=2\n    )\n    \n    # 레이아웃 설정\n    fig.update_layout(\n        title='🔐 부채널 분석: TVLA를 이용한 정보 누설 탐지',\n        height=800\n    )\n    \n    fig.update_xaxes(title_text='전력 소비 (mW)', row=1, col=1)\n    fig.update_yaxes(title_text='|t-statistic|', row=1, col=2)\n    fig.update_xaxes(title_text='시간 (샘플)', row=2, col=1)\n    fig.update_yaxes(title_text='전력 (mW)', row=2, col=1)\n    fig.update_xaxes(title_text='노이즈 레벨 (σ)', row=2, col=2)\n    fig.update_yaxes(title_text='탐지 횟수 (/100)', row=2, col=2)\n    \n    print(\"\\n💡 부채널 분석에서 Welch's t-test가 중요한 이유:\")\n    print(\"  1. 암호 연산의 복잡도에 따라 전력 소비 분산이 다름\")\n    print(\"  2. 측정 환경 노이즈가 상황에 따라 변함\")\n    print(\"  3. 잘못된 통계 검정은 보안 취약점을 놓칠 수 있음\")\n    print(\"  4. TVLA 표준에서도 Welch's t-test 권장\")\n    \n    return fig\n\n# 예제 4 실행\nfig4 = side_channel_analysis_example()\nfig4.show()\n\n# ====================================================\n# 예제 5: 고급 TVLA - 1st Order vs Higher Order 분석\n# ====================================================\n\ndef advanced_tvla_example():\n    \"\"\"고급 TVLA: 1차 및 고차 부채널 분석\"\"\"\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"🔬 고급 TVLA: 마스킹 대응책 평가\")\n    print(\"=\" * 70)\n    \n    np.random.seed(42)\n    n_traces = 1000\n    \n    # 시나리오: 마스킹된 암호 구현 평가\n    # 1차 마스킹은 1st order 공격을 방어하지만 2nd order에는 취약\n    \n    # 고정 vs 랜덤 데이터에서의 전력 소비\n    # 마스킹 없음 (취약한 구현)\n    unmasked_fixed = np.random.normal(100, 3, n_traces)\n    unmasked_random = np.random.normal(105, 3, n_traces)  # 명확한 차이\n    \n    # 1차 마스킹 (1st order 방어)\n    masked_fixed = np.random.normal(100, 5, n_traces)\n    masked_random = np.random.normal(100.5, 5, n_traces)  # 작은 차이\n    \n    # 2nd order 분석을 위한 제곱값\n    masked_fixed_sq = (masked_fixed - np.mean(masked_fixed))**2\n    masked_random_sq = (masked_random - np.mean(masked_random))**2\n    # 제곱하면 분산이 달라짐!\n    masked_random_sq = masked_random_sq * 1.5  # 인위적으로 차이 생성\n    \n    # 1st order TVLA\n    t_unmasked_student, _ = stats.ttest_ind(unmasked_fixed, unmasked_random)\n    t_unmasked_welch, _ = stats.ttest_ind(unmasked_fixed, unmasked_random, equal_var=False)\n    \n    t_masked_student, _ = stats.ttest_ind(masked_fixed, masked_random)\n    t_masked_welch, _ = stats.ttest_ind(masked_fixed, masked_random, equal_var=False)\n    \n    # 2nd order TVLA (제곱값에 대한 분석)\n    t_2nd_student, _ = stats.ttest_ind(masked_fixed_sq, masked_random_sq)\n    t_2nd_welch, _ = stats.ttest_ind(masked_fixed_sq, masked_random_sq, equal_var=False)\n    \n    # Levene 검정\n    _, levene_2nd = stats.levene(masked_fixed_sq, masked_random_sq)\n    \n    print(f\"\\n📊 1st Order TVLA 결과:\")\n    print(f\"  마스킹 없음:\")\n    print(f\"    Student's: |t| = {abs(t_unmasked_student):.2f} {'🚨 누설!' if abs(t_unmasked_student) > 4.5 else '✅'}\")\n    print(f\"    Welch's:   |t| = {abs(t_unmasked_welch):.2f} {'🚨 누설!' if abs(t_unmasked_welch) > 4.5 else '✅'}\")\n    print(f\"  마스킹 적용:\")\n    print(f\"    Student's: |t| = {abs(t_masked_student):.2f} {'🚨 누설!' if abs(t_masked_student) > 4.5 else '✅ 안전'}\")\n    print(f\"    Welch's:   |t| = {abs(t_masked_welch):.2f} {'🚨 누설!' if abs(t_masked_welch) > 4.5 else '✅ 안전'}\")\n    \n    print(f\"\\n📊 2nd Order TVLA 결과 (제곱값 분석):\")\n    print(f\"  분산비: {np.var(masked_random_sq) / np.var(masked_fixed_sq):.2f}\")\n    print(f\"  Levene p-value: {levene_2nd:.6f} {'→ 이분산!' if levene_2nd < 0.05 else ''}\")\n    print(f\"  Student's: |t| = {abs(t_2nd_student):.2f} {'🚨 2차 누설!' if abs(t_2nd_student) > 4.5 else '✅'}\")\n    print(f\"  Welch's:   |t| = {abs(t_2nd_welch):.2f} {'🚨 2차 누설!' if abs(t_2nd_welch) > 4.5 else '✅'}\")\n    \n    # 시각화\n    fig = make_subplots(\n        rows=2, cols=2,\n        subplot_titles=[\n            '마스킹 없음: 1st Order',\n            '마스킹 적용: 1st Order',\n            '마스킹 적용: 2nd Order (원본)',\n            '마스킹 적용: 2nd Order (제곱)'\n        ]\n    )\n    \n    # 1. 마스킹 없음\n    fig.add_trace(\n        go.Histogram(x=unmasked_fixed, name='Fixed', opacity=0.6,\n                     marker_color='blue', nbinsx=30),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Histogram(x=unmasked_random, name='Random', opacity=0.6,\n                     marker_color='red', nbinsx=30),\n        row=1, col=1\n    )\n    \n    # 2. 1차 마스킹 (1st order)\n    fig.add_trace(\n        go.Histogram(x=masked_fixed, name='Fixed', opacity=0.6,\n                     marker_color='blue', nbinsx=30),\n        row=1, col=2\n    )\n    fig.add_trace(\n        go.Histogram(x=masked_random, name='Random', opacity=0.6,\n                     marker_color='red', nbinsx=30),\n        row=1, col=2\n    )\n    \n    # 3. 1차 마스킹 원본 데이터\n    fig.add_trace(\n        go.Box(y=masked_fixed, name='Fixed', marker_color='blue'),\n        row=2, col=1\n    )\n    fig.add_trace(\n        go.Box(y=masked_random, name='Random', marker_color='red'),\n        row=2, col=1\n    )\n    \n    # 4. 2nd order (제곱값)\n    fig.add_trace(\n        go.Box(y=masked_fixed_sq, name='Fixed²', marker_color='blue'),\n        row=2, col=2\n    )\n    fig.add_trace(\n        go.Box(y=masked_random_sq, name='Random²', marker_color='red'),\n        row=2, col=2\n    )\n    \n    fig.update_layout(\n        title='🔬 고급 TVLA: 1st vs 2nd Order 부채널 분석',\n        height=700\n    )\n    \n    print(\"\\n💡 핵심 통찰:\")\n    print(\"  1. 2nd order 분석에서는 비선형 변환으로 분산이 크게 달라짐\")\n    print(\"  2. Student's t-test는 이분산 상황에서 부정확할 수 있음\")\n    print(\"  3. Welch's t-test가 더 신뢰할 수 있는 결과 제공\")\n    print(\"  4. 보안 평가에서 통계적 정확성은 매우 중요!\")\n    \n    return fig\n\n# 예제 5 실행\nfig5 = advanced_tvla_example()\nfig5.show()\n\nprint(\"\\n\" + \"🔐\" * 35)\nprint(\"\\n📌 부채널 분석과 TVLA 최종 요약:\")\nprint(\"  • TVLA는 암호 구현의 부채널 누설을 탐지하는 표준 방법\")\nprint(\"  • |t| > 4.5를 임계값으로 사용 (99.999% 신뢰수준)\")\nprint(\"  • 암호 연산은 본질적으로 이분산을 생성\")\nprint(\"  • Welch's t-test가 더 정확한 보안 평가 제공\")\nprint(\"  • 잘못된 통계는 보안 취약점을 놓칠 위험!\")\nprint(\"\\n\" + \"🔐\" * 35)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "practical-guide",
   "metadata": {},
   "source": [
    "## 💡 3. 실용적 가이드라인\n",
    "\n",
    "### 🎯 **언제 어떤 검정을 사용할까?**\n",
    "\n",
    "#### 🔄 **결정 흐름도**:\n",
    "\n",
    "```\n",
    "데이터 준비\n",
    "    ↓\n",
    "정규성 확인 (Shapiro-Wilk, Q-Q plot)\n",
    "    ↓\n",
    "정규성 만족? ──NO──→ 비모수 검정 (Mann-Whitney U)\n",
    "    ↓ YES\n",
    "등분산성 확인 (Levene 검정)\n",
    "    ↓\n",
    "등분산성 만족? ──NO──→ Welch's t-test\n",
    "    ↓ YES\n",
    "Student's t-test 또는 Welch's t-test\n",
    "(사실상 Welch's를 추천)\n",
    "```\n",
    "\n",
    "### 📊 **경험법칙**:\n",
    "\n",
    "1. **분산비 확인**:\n",
    "   - 분산비 < 2: 두 방법 모두 안전\n",
    "   - 분산비 ≥ 2: Welch's t-test 필수\n",
    "\n",
    "2. **표본크기**:\n",
    "   - 균등 (n₁ ≈ n₂): 상대적으로 안전\n",
    "   - 불균등: Welch's t-test 강력 권장\n",
    "\n",
    "3. **안전한 선택**:\n",
    "   - **항상 Welch's t-test 사용**\n",
    "   - 등분산이어도 성능 거의 동일\n",
    "   - 이분산일 때 훨씬 안전\n",
    "\n",
    "### ⚠️ **주의사항**:\n",
    "\n",
    "- **독립성**: 통계로 확인 불가, 연구설계로 보장\n",
    "- **정규성**: 심한 위반시 변환 또는 비모수 검정\n",
    "- **이상치**: 제거 전 신중한 검토 필요\n",
    "\n",
    "### 🏆 **최종 권장사항**:\n",
    "\n",
    "> **\"의심스러우면 Welch's t-test를 사용하라\"**\n",
    "> \n",
    "> - 현대 통계 소프트웨어의 기본값\n",
    "> - 더 안전하고 강건한 방법\n",
    "> - 성능 손실 거의 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 📚 핵심 요약\n",
    "\n",
    "### ✨ **오늘 배운 것들**\n",
    "\n",
    "1. **t-검정의 3대 가정** 🎯\n",
    "   - 정규성, 등분산성, 독립성\n",
    "   - 각 가정의 확인 방법과 위반시 영향\n",
    "\n",
    "2. **Welch's t-test의 우수성** 🛡️\n",
    "   - 등분산성 가정 불필요\n",
    "   - Satterthwaite 근사법으로 자유도 조정\n",
    "   - 더 강건하고 안전한 방법\n",
    "\n",
    "3. **실무 가이드라인** 💼\n",
    "   - 분산비 > 2배시 Welch's 필수\n",
    "   - 의심스러우면 항상 Welch's 사용\n",
    "   - 현대 통계의 표준 접근법\n",
    "\n",
    "### 🔑 **핵심 메시지**\n",
    "\n",
    "> **\"완벽한 가정을 만족하는 데이터는 드물다.  \n",
    "> 현실을 인정하고 적절한 도구를 사용하자!\"**\n",
    "\n",
    "### 🚀 **다음 단계**\n",
    "\n",
    "이제 우리는 가정 위반에 대처하는 법을 알았습니다!  \n",
    "다음에는 **부채널 분석과 실제 비즈니스 적용**에서 t-검정을 어떻게 사용하는지 살펴보겠습니다.\n",
    "\n",
    "**다음 노트북**: `05_real_world_applications.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "*\"통계학은 불완전한 세상에서 최선의 결론을 내리는 예술이다\"* - Bernard Welch의 정신을 기리며 🎓"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}